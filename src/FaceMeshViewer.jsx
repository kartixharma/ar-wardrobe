import React, { useEffect, useRef, useState } from "react";
import * as tf from "@tensorflow/tfjs";
import * as faceLandmarksDetection from "@tensorflow-models/face-landmarks-detection";
import "@tensorflow/tfjs-backend-webgl";
import { TRIANGULATION } from "./triangulation.js";
import * as THREE from "three";

const VIDEO_WIDTH = 720;
const VIDEO_HEIGHT = 620;

// Face mesh regions for realistic occlusion
const FACE_OCCLUDER_LANDMARKS = {
Â  faceContour: [
Â  Â  10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,
Â  Â  397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,
Â  Â  172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109
Â  ],
Â  leftEye: [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246],
Â  rightEye: [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398],
Â  nose: [1, 2, 5, 4, 6, 168, 8, 9, 10, 151, 195, 197, 196, 3, 51, 48, 115, 131, 134, 102, 49],
Â  forehead: [10, 151, 9, 337, 299, 333, 298, 301, 284, 251]
};

export default function FaceMeshViewer({ glassesModelPath, setDebugInfo, setIsGlassesLoaded, setIsModelLoaded, setStatus }) {
Â  const videoRef = useRef(null);
Â  const threeContainerRef = useRef(null);
Â  const animationRef = useRef(null);
Â  const detectorRef = useRef(null);
Â  const sceneRef = useRef(null);
Â  const rendererRef = useRef(null);
Â  const cameraRef = useRef(null);
Â  const glassesRef = useRef(null);
Â  const faceOccluderRef = useRef(null);
  const [isSceneReady, setIsSceneReady] = useState(false);

  // This effect hook handles loading and changing the glasses model
  useEffect(() => {
    if (!isSceneReady || !glassesModelPath) return;

    async function loadGlassesModel(path) {
      try {
        // Remove the previous glasses model if it exists
        if (glassesRef.current && sceneRef.current) {
          sceneRef.current.remove(glassesRef.current);
          glassesRef.current = null;
        }
        setIsGlassesLoaded(false);
        setStatus(`Loading glasses model: ${path.split('/').pop()}`);

        const { GLTFLoader } = await import("three/examples/jsm/loaders/GLTFLoader.js");
        const loader = new GLTFLoader();

        loader.load(
          path,
          (gltf) => {
            console.log(`Glasses model loaded from ${path}`);
            const glasses = gltf.scene;

            glasses.traverse((child) => {
              if (child.isMesh) {
                child.material.depthTest = true;
                child.material.depthWrite = true;
              }
            });

            glasses.scale.set(0.1, 0.1, 0.1);
            glasses.position.set(0, 0, 0);
            glasses.visible = true;
            glasses.renderOrder = 0; // Render after occluder

            sceneRef.current.add(glasses);
            glassesRef.current = glasses;
            setIsGlassesLoaded(true);
            setStatus("Glasses model loaded successfully!");
          },
          (progress) => {
            const percent = ((progress.loaded / progress.total) * 100).toFixed(0);
            setStatus(`Loading glasses... ${percent}%`);
          },
          (error) => {
            console.error(`Error loading glasses model from ${path}:`, error);
            setStatus("Failed to load glasses model");
            createFallbackCube();
          }
        );
      } catch (err) {
        console.error("Error setting up glasses loader:", err);
        createFallbackCube();
        throw err;
      }
    }

    loadGlassesModel(glassesModelPath);

  }, [glassesModelPath, isSceneReady]);


Â  useEffect(() => {
Â  Â  let isRunning = true;

Â  Â  async function initCamera() {
Â  Â  Â  try {
Â  Â  Â  Â  setStatus("Requesting camera access...");
Â  Â  Â  Â  const stream = await navigator.mediaDevices.getUserMedia({
Â  Â  Â  Â  Â  video: {
Â  Â  Â  Â  Â  Â  width: VIDEO_WIDTH,
Â  Â  Â  Â  Â  Â  height: VIDEO_HEIGHT,
Â  Â  Â  Â  Â  Â  facingMode: "user",
Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  audio: false,
Â  Â  Â  Â  });

Â  Â  Â  Â  if (videoRef.current) {
Â  Â  Â  Â  Â  videoRef.current.srcObject = stream;
Â  Â  Â  Â  Â  return new Promise((resolve) => {
Â  Â  Â  Â  Â  Â  videoRef.current.onloadedmetadata = () => {
Â  Â  Â  Â  Â  Â  Â  setStatus("Camera ready");
Â  Â  Â  Â  Â  Â  Â  resolve();
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  });
Â  Â  Â  Â  }
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Camera access denied:", err);
Â  Â  Â  Â  setStatus("Camera access denied");
Â  Â  Â  Â  throw err;
Â  Â  Â  }
Â  Â  }

Â  Â  async function initThreeJS() {
Â  Â  Â  try {
Â  Â  Â  Â  setStatus("Initializing 3D scene...");

Â  Â  Â  Â  const scene = new THREE.Scene();
Â  Â  Â  Â  const camera = new THREE.PerspectiveCamera(50,VIDEO_WIDTH / VIDEO_HEIGHT,0.01,100);
Â  Â  Â  Â  const renderer = new THREE.WebGLRenderer({alpha: true,antialias: true,stencil: true});

Â  Â  Â  Â  renderer.setSize(VIDEO_WIDTH, VIDEO_HEIGHT);
Â  Â  Â  Â  renderer.setClearColor(0x000000, 0);
Â  Â  Â  Â  renderer.domElement.style.position = "absolute";
Â  Â  Â  Â  renderer.domElement.style.top = "0";
Â  Â  Â  Â  renderer.domElement.style.left = "0";
Â  Â  Â  Â  renderer.domElement.style.pointerEvents = "none";
Â  Â  Â  Â  renderer.sortObjects = true;
Â  Â  Â  Â  renderer.shadowMap.enabled = false;

Â  Â  Â  Â  if (threeContainerRef.current) {
Â  Â  Â  Â  Â  threeContainerRef.current.appendChild(renderer.domElement);
Â  Â  Â  Â  }

Â  Â  Â  Â  const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
Â  Â  Â  Â  scene.add(ambientLight);
Â  Â  Â  Â  const directionalLight = new THREE.DirectionalLight(0xffffff, 0.6);
Â  Â  Â  Â  directionalLight.position.set(0, 1, 0.5);
Â  Â  Â  Â  scene.add(directionalLight);

Â  Â  Â  Â  camera.position.set(0, 0, 1);
Â  Â  Â  Â  camera.lookAt(0, 0, 0);

Â  Â  Â  Â  sceneRef.current = scene;
Â  Â  Â  Â  rendererRef.current = renderer;
Â  Â  Â  Â  cameraRef.current = camera;
        setIsSceneReady(true); // Signal that the scene is ready for models to be loaded

Â  Â  Â  Â  setStatus("3D scene initialized");
Â  Â  Â  Â  return { scene, camera, renderer };
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Three.js initialization error:", err);
Â  Â  Â  Â  setStatus("3D initialization failed");
Â  Â  Â  Â  throw err;
Â  Â  Â  }
Â  Â  }

Â  Â  function createRealisticFaceOccluder() {
Â  Â  Â  if (!sceneRef.current) return;
Â  Â  Â  console.log("Creating realistic face occluder mesh");
Â  Â  Â  const occluderGeometry = new THREE.BufferGeometry();
Â  Â  Â  const occluderMaterial = new THREE.MeshBasicMaterial({
Â  Â  Â  Â  color: 0x000000,
Â  Â  Â  Â  depthWrite: true,
Â  Â  Â  Â  depthTest: true, Â 
Â  Â  Â  Â  colorWrite: false, 
Â  Â  Â  Â  side: THREE.DoubleSide,
Â  Â  Â  Â  opacity: 0 Â 
Â  Â  Â  });

Â  Â  Â  const occluder = new THREE.Mesh(occluderGeometry, occluderMaterial);
Â  Â  Â  occluder.renderOrder = -1;
Â  Â  Â  occluder.visible = false;

Â  Â  Â  sceneRef.current.add(occluder);
Â  Â  Â  faceOccluderRef.current = occluder;
Â  Â  Â  console.log("Realistic face occluder created");
Â  Â  }

Â  Â  function updateRealisticFaceOccluder(landmarks) {
Â  Â  Â  if (!faceOccluderRef.current || !landmarks || landmarks.length < 468) {
Â  Â  Â  Â  if (faceOccluderRef.current) faceOccluderRef.current.visible = false;
Â  Â  Â  Â  return;
Â  Â  Â  }
Â  Â  Â  try {
Â  Â  Â  Â  const occluderIndices = [
Â  Â  Â  Â  Â  ...FACE_OCCLUDER_LANDMARKS.faceContour,
Â  Â  Â  Â  Â  ...FACE_OCCLUDER_LANDMARKS.leftEye,
Â  Â  Â  Â  Â  ...FACE_OCCLUDER_LANDMARKS.rightEye,
Â  Â  Â  Â  Â  ...FACE_OCCLUDER_LANDMARKS.nose,
Â  Â  Â  Â  Â  ...FACE_OCCLUDER_LANDMARKS.forehead
Â  Â  Â  Â  ];
Â  Â  Â  Â  const uniqueIndices = [...new Set(occluderIndices)];
Â  Â  Â  Â  const vertices = [];
Â  Â  Â  Â  const validLandmarks = [];

Â  Â  Â  Â  uniqueIndices.forEach(idx => {
Â  Â  Â  Â  Â  if (landmarks[idx]) {
Â  Â  Â  Â  Â  Â  const landmark = landmarks[idx];
Â  Â  Â  Â  Â  Â  const worldPos = uvToWorld(
Â  Â  Â  Â  Â  Â  Â  landmark.x / VIDEO_WIDTH,
Â  Â  Â  Â  Â  Â  Â  landmark.y / VIDEO_HEIGHT,
Â  Â  Â  Â  Â  Â  Â  -0.15
Â  Â  Â  Â  Â  Â  );
Â  Â  Â  Â  Â  Â  vertices.push(worldPos.x, worldPos.y, worldPos.z);
Â  Â  Â  Â  Â  Â  validLandmarks.push(landmark);
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });
Â  Â  Â  Â  if (vertices.length < 9) {
Â  Â  Â  Â  Â  faceOccluderRef.current.visible = false;
Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }
Â  Â  Â  Â  const occluder = faceOccluderRef.current;
Â  Â  Â  Â  const geometry = occluder.geometry;
Â  Â  Â  Â  geometry.setAttribute("position",new THREE.Float32BufferAttribute(vertices, 3));
Â  Â  Â  Â  const triangles = [];
Â  Â  Â  Â  const numPoints = vertices.length / 3;
Â  Â  Â  Â  const centerIdx = Math.floor(numPoints / 2);
Â  Â  Â  Â  for (let i = 0; i < numPoints; i++) {
Â  Â  Â  Â  Â  if (i !== centerIdx) {
Â  Â  Â  Â  Â  Â  const next = (i + 1) % numPoints;
Â  Â  Â  Â  Â  Â  if (next !== centerIdx) {
Â  Â  Â  Â  Â  Â  Â  triangles.push(centerIdx, i, next);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  for (let i = 0; i < Math.min(numPoints - 2, 20); i++) {
Â  Â  Â  Â  Â  triangles.push(i, i + 1, i + 2);
Â  Â  Â  Â  }
Â  Â  Â  Â  geometry.setIndex(triangles);
Â  Â  Â  Â  geometry.computeVertexNormals();
Â  Â  Â  Â  occluder.visible = true;
Â  Â  Â  Â  // console.log(`Face occluder updated with ${numPoints} points, ${triangles.length/3} triangles`);
Â  Â  Â  } catch (error) {
Â  Â  Â  Â  console.warn("Failed to update realistic face occluder:", error);
Â  Â  Â  Â  if (faceOccluderRef.current) faceOccluderRef.current.visible = false;
Â  Â  Â  }
Â  Â  }

Â  Â  function createFallbackCube() {
Â  Â  Â  if (!sceneRef.current) return;
Â  Â  Â  console.log("Creating fallback debugging cube");
Â  Â  Â  const geometry = new THREE.BoxGeometry(0.1, 0.1, 0.1);
Â  Â  Â  geometry.computeBoundingSphere();
Â  Â  Â  geometry.computeBoundingBox();
Â  Â  Â  const material = new THREE.MeshBasicMaterial({color: 0x00ff00,wireframe: false,transparent: true,opacity: 0.8});
Â  Â  Â  const cube = new THREE.Mesh(geometry, material);
Â  Â  Â  cube.position.set(0, 0, -0.3);
Â  Â  Â  cube.visible = true;
Â  Â  Â  cube.renderOrder = 1;
Â  Â  Â  sceneRef.current.add(cube);
Â  Â  Â  glassesRef.current = cube;
Â  Â  Â  setIsGlassesLoaded(true);
Â  Â  Â  setStatus("Using DEBUG CUBE with realistic face occlusion");
Â  Â  Â  console.log("Debug cube created at position:", cube.position);
Â  Â  }

Â  Â  async function loadFaceMeshModel() {
Â  Â  Â  try {
Â  Â  Â  Â  setStatus("Loading TensorFlow...");
Â  Â  Â  Â  await tf.ready();
Â  Â  Â  Â  console.log("TensorFlow ready");
Â  Â  Â  Â  setStatus("Loading MediaPipe FaceMesh model...");
Â  Â  Â  Â  const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
Â  Â  Â  Â  const detectorConfig = {runtime: "tfjs",maxFaces: 1,refineLandmarks: true};
Â  Â  Â  Â  const detector = await faceLandmarksDetection.createDetector(model,detectorConfig);
Â  Â  Â  Â  detectorRef.current = detector;
Â  Â  Â  Â  setIsModelLoaded(true);
Â  Â  Â  Â  setStatus("MediaPipe FaceMesh loaded successfully!");
Â  Â  Â  Â  console.log("MediaPipe FaceMesh model loaded successfully");
Â  Â  Â  Â  return detector;
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Error loading MediaPipe model:", err);
Â  Â  Â  Â  setStatus("Model loading failed, using simulation");
Â  Â  Â  Â  setIsModelLoaded(false);
Â  Â  Â  Â  return null;
Â  Â  Â  }
Â  Â  }

Â  Â  function uvToWorld(u, v, planeZ = 0) {
Â  Â  Â  const cam = cameraRef.current;
Â  Â  Â  const ndc = new THREE.Vector3(u * 2 - 1, 1 - v * 2, 0.5);
Â  Â  Â  ndc.unproject(cam);
Â  Â  Â  const dir = ndc.sub(cam.position).normalize();
Â  Â  Â  const t = (planeZ - cam.position.z) / dir.z;
Â  Â  Â  return cam.position.clone().add(dir.multiplyScalar(t));
Â  Â  }

Â  Â  function getFaceAlignment(landmarks) {
Â  Â  Â  try {
Â  Â  Â  Â  const leftEyeCenter = landmarks[159];
Â  Â  Â  Â  const rightEyeCenter = landmarks[386];
Â  Â  Â  Â  const noseTip = landmarks[1];
Â  Â  Â  Â  const glassesCenter = {x: (leftEyeCenter.x + rightEyeCenter.x) / 2,y: (leftEyeCenter.y + rightEyeCenter.y) / 2 + 0.01,z: (leftEyeCenter.z + rightEyeCenter.z) / 2 - 0.05,};
Â  Â  Â  Â  const normalizedGlassesCenter = {x: glassesCenter.x / VIDEO_WIDTH,y: glassesCenter.y / VIDEO_HEIGHT - 0.02,z: glassesCenter.z / VIDEO_WIDTH};
Â  Â  Â  Â  const u = normalizedGlassesCenter.x;
Â  Â  Â  Â  const v = normalizedGlassesCenter.y;
Â  Â  Â  Â  const targetZ = -0.1;
Â  Â  Â  Â  const world = uvToWorld(u, v, targetZ);
Â  Â  Â  Â  const position = { x: world.x, y: world.y, z: world.z };
Â  Â  Â  Â  const eyeDistancePixels = Math.sqrt(Math.pow(rightEyeCenter.x - leftEyeCenter.x, 2) + Math.pow(rightEyeCenter.y - leftEyeCenter.y, 2) + Math.pow(rightEyeCenter.z - leftEyeCenter.z, 2));
Â  Â  Â  Â  const eyeDistanceNormalized = eyeDistancePixels / VIDEO_WIDTH;
Â  Â  Â  Â  const scale = Math.max(0.5, Math.min(4.0, eyeDistanceNormalized * 20));
Â  Â  Â  Â  const eyeVectorPixels = {x: rightEyeCenter.x - leftEyeCenter.x,y: rightEyeCenter.y - leftEyeCenter.y,};
Â  Â  Â  Â  const roll = -Math.atan2(eyeVectorPixels.y, eyeVectorPixels.x);
Â  Â  Â  Â  const eyeMidpointPixels = {x: (leftEyeCenter.x + rightEyeCenter.x) / 2,y: (leftEyeCenter.y + rightEyeCenter.y) / 2};
Â  Â  Â  Â  const noseOffsetPixels = noseTip.x - eyeMidpointPixels.x;
Â  Â  Â  Â  const yaw = Math.atan2(noseOffsetPixels, eyeDistancePixels) * 0.8;
Â  Â  Â  Â  const noseOffsetY = noseTip.y - eyeMidpointPixels.y;
Â  Â  Â  Â  const pitch = Math.atan2(noseOffsetY, eyeDistancePixels * 0.8) - 0.8;
Â  Â  Â  Â  return {position,rotation: { pitch, yaw, roll },scale};
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Error calculating face alignment:", err);
Â  Â  Â  Â  return {position: { x: 0, y: 0, z: -0.3 },rotation: { pitch: 0, yaw: 0, roll: 0 },scale: 1};
Â  Â  Â  }
Â  Â  }

Â  Â  function updateGlassesAlignment(alignment) {
Â  Â  Â  if (!glassesRef.current) return;
Â  Â  Â  const { position, rotation, scale } = alignment;
Â  Â  Â  glassesRef.current.visible = true;
Â  Â  Â  glassesRef.current.position.set(position.x, position.y, position.z);
Â  Â  Â  glassesRef.current.rotation.x = rotation.pitch;
Â  Â  Â  glassesRef.current.rotation.y = rotation.yaw;
Â  Â  Â  glassesRef.current.rotation.z = rotation.roll;
Â  Â  Â  const clampedScale = Math.max(0.1, Math.min(4.0, scale));
Â  Â  Â  glassesRef.current.scale.setScalar(clampedScale);
Â  Â  Â  glassesRef.current.updateMatrix();
Â  Â  Â  glassesRef.current.updateMatrixWorld(true);
Â  Â  Â  setDebugInfo(`Pos: (${position.x.toFixed(2)}, ${position.y.toFixed(2)}, ${position.z.toFixed(2)}) Scale: ${clampedScale.toFixed(2)}`);
Â  Â  Â  if (rendererRef.current && sceneRef.current && cameraRef.current) {
Â  Â  Â  Â  rendererRef.current.clear(false, true, false);
Â  Â  Â  Â  rendererRef.current.render(sceneRef.current, cameraRef.current);
Â  Â  Â  }
Â  Â  }

Â  Â  function getSimulatedAlignment() {
Â  Â  Â  const time = Date.now() * 0.001;
Â  Â  Â  return {
Â  Â  Â  Â  position: { x: 0, y: 0, z: -0.3 },
Â  Â  Â  Â  rotation: {pitch: Math.sin(time * 0.7) * 0.1,yaw: Math.sin(time * 0.5) * 0.2,roll: Math.sin(time * 0.3) * 0.1},
Â  Â  Â  Â  scale: 1.0,
Â  Â  Â  };
Â  Â  }

Â  Â  async function detectLoop() {
Â  Â  Â  if (!isRunning) return;
Â  Â  Â  let alignment = {position: { x: 0, y: 0, z: -0.3 },rotation: { pitch: 0, yaw: 0, roll: 0 },scale: 1.0};
Â  Â  Â  try {
Â  Â  Â  Â  if (detectorRef.current && videoRef.current && videoRef.current.readyState === 4) {
Â  Â  Â  Â  Â  const predictions = await detectorRef.current.estimateFaces(videoRef.current,{flipHorizontal: false});
Â  Â  Â  Â  Â  if (predictions.length > 0) {
Â  Â  Â  Â  Â  Â  const face = predictions[0];
Â  Â  Â  Â  Â  Â  if (face.keypoints && face.keypoints.length > 400) {
Â  Â  Â  Â  Â  Â  Â  alignment = getFaceAlignment(face.keypoints);
Â  Â  Â  Â  Â  Â  Â  updateRealisticFaceOccluder(face.keypoints);
Â  Â  Â  Â  Â  Â  Â  // setStatus(`ğŸ§ Headphones aligned! Tracking ${predictions.length} face(s)`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  setStatus("ğŸ‘‹ No face detected - show your face to the camera");
Â  Â  Â  Â  Â  Â  if (faceOccluderRef.current) faceOccluderRef.current.visible = false;
Â  Â  Â  Â  Â  Â  alignment = {position: { x: 0, y: 0, z: -0.3 },rotation: { pitch: 0, yaw: 0, roll: 0 },scale: 2.5};
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  alignment = getSimulatedAlignment();
Â  Â  Â  Â  Â  if (!detectorRef.current) setStatus("ğŸ¤– Simulation mode (model not loaded)");
Â  Â  Â  Â  }
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Detection error:", err);
Â  Â  Â  Â  alignment = getSimulatedAlignment();
Â  Â  Â  Â  setStatus("âš ï¸ Detection error - using simulation");
Â  Â  Â  }
Â  Â  Â  updateGlassesAlignment(alignment);
Â  Â  Â  animationRef.current = requestAnimationFrame(detectLoop);
Â  Â  }

Â  Â  async function init() {
Â  Â  Â  try {
Â  Â  Â  Â  await initCamera();
Â  Â  Â  Â  await initThreeJS();
Â  Â  Â  Â  createRealisticFaceOccluder();
        // The glasses model loading is now handled by the useEffect hook watching `glassesModelPath`
Â  Â  Â  Â  detectLoop();
Â  Â  Â  Â  await loadFaceMeshModel();
Â  Â  Â  Â  if (videoRef.current && videoRef.current.readyState < 4) {
Â  Â  Â  Â  Â  await videoRef.current.play();
Â  Â  Â  Â  }
Â  Â  Â  Â  console.log("Initialization complete");
Â  Â  Â  } catch (err) {
Â  Â  Â  Â  console.error("Initialization error:", err);
Â  Â  Â  Â  setStatus("Initialization failed");
Â  Â  Â  }
Â  Â  }

Â  Â  init();

Â  Â  return () => {
Â  Â  Â  isRunning = false;
Â  Â  Â  if (animationRef.current) cancelAnimationFrame(animationRef.current);
Â  Â  Â  if (videoRef.current?.srcObject) videoRef.current.srcObject.getTracks().forEach((track) => track.stop());
Â  Â  Â  if (rendererRef.current) rendererRef.current.dispose();
Â  Â  Â  if (faceOccluderRef.current?.geometry) faceOccluderRef.current.geometry.dispose();
Â  Â  Â  if (faceOccluderRef.current?.material) faceOccluderRef.current.material.dispose();
Â  Â  };
Â  }, []);

Â  return (
Â  Â  <div style={{position: "relative",width: VIDEO_WIDTH,height: VIDEO_HEIGHT,backgroundColor: "#000",borderRadius: "16px",overflow: "hidden"}}>
Â  Â  Â  <video ref={videoRef} width={VIDEO_WIDTH} height={VIDEO_HEIGHT} style={{position: "absolute",top: 0,left: 0,zIndex: 0,transform: "scaleX(1)",objectFit: "cover"}} autoPlay muted playsInline/>
Â  Â  Â  <div ref={threeContainerRef} style={{position: "absolute",top: 0,left: 0,zIndex: 1,pointerEvents: "none"}}/>
Â  Â  </div>
Â  );
}